{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Agri Cult Final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "A_jO5nOc27G4",
        "outputId": "9d6cbf0a-a18b-4716-cd5a-731df1815887"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "\n",
        "market_price = pd.read_csv('market.csv')\n",
        "standard_price = pd.read_csv('standard.csv')\n",
        "coc = pd.read_csv('cost-of-cultivation.csv')\n",
        "coc.head(),standard_price.head(),market_price.head()\n",
        "\n",
        "#list of considered crops\n",
        "products=list(coc['crop'])  # [\"groundnut\", \"paddy\", \"rice\", \"wheat\", \"barley\", \"jowar\", \"bajra\", \"maize\", \"ragi\"]\n",
        "market_edited=market_price[market_price['commodity'].isin([x.capitalize() for x in products ])]\n",
        "market_edited.head()\n",
        "\n",
        "#take mean of all varieties of one crop\n",
        "grouped_market = market_edited.groupby(['state', 'commodity']).agg(['mean']).reset_index()\n",
        "grouped_market.columns = [\"\".join(x) for x in grouped_market.columns]\n",
        "grouped_market.head()\n",
        "\n",
        "#convert price in quintal to price in kg\n",
        "grouped_market['modal_pricemean'] = grouped_market['modal_pricemean'].apply(lambda x: float(x)/100)\n",
        "standard_price['price'] = standard_price['price'].apply(lambda x: float(x)/100)\n",
        "grouped_market.head(),standard_price.head()\n",
        "\n",
        "#convert to dictionary of crop to profit or cost\n",
        "std_prices = dict(zip(standard_price.standard, standard_price.price))\n",
        "coc_dict = dict(zip(coc.crop, coc.cost))\n",
        "std_prices,coc_dict\n",
        "\n",
        "\n",
        "#state vs crop matrix\n",
        "yield_mat = pd.read_csv('state-crop-yield.csv')\n",
        "yield_mat.head()\n",
        "\n",
        "#state and crop lists\n",
        "states = yield_mat['state']\n",
        "crops = list(yield_mat.columns)[1:]\n",
        "yield_np_mat = np.matrix(yield_mat)\n",
        "prediction_table = {'State':[],\n",
        "                    'Crop':[],\n",
        "                    'Profit':[]}\n",
        "yield_np_mat.shape\n",
        "\n",
        "\n",
        "for i in range(0,yield_np_mat.shape[0]-1):\n",
        "    for j in range(1,yield_np_mat.shape[1]):\n",
        "        if(yield_np_mat[i,j]!=0.0):\n",
        "\t    #if yielding in current state then calculate profit\n",
        "            rs_per_kg = grouped_market[(grouped_market['state']==states[i]) & (grouped_market['commodity'] == crops[j-1])]['modal_pricemean']\n",
        "            if(rs_per_kg.shape[0]==1):\n",
        "\t\t#use market price data\n",
        "                diff = ((yield_np_mat[i,j]) * rs_per_kg.values[0]) - coc_dict[str(crops[j-1].lower())]\n",
        "                val = diff if diff>0.0 else 1.0\n",
        "            else:\n",
        "\t\t#use approximated standard price\n",
        "                diff = ((yield_np_mat[i,j]) * std_prices[str(crops[j-1].lower())]) - coc_dict[str(crops[j-1].lower())]\n",
        "                val = diff if diff>0.0 else 1.0\n",
        "            \n",
        "\t    #append all results to a table\n",
        "            prediction_table['State'].append(states[i])\n",
        "            prediction_table['Crop'].append(crops[j-1])\n",
        "            prediction_table['Profit'].append(val)\n",
        "        else:\n",
        "\t    #states which cant produce the given crop\n",
        "            #print(\"**\", states[i],crops[j-1])\n",
        "            prediction_table['State'].append(states[i])\n",
        "            prediction_table['Crop'].append(crops[j-1])\n",
        "            prediction_table['Profit'].append(-1)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "#\n",
        "plt.figure(figsize=((10,8)))\n",
        "data1={ 'crop':[],\n",
        "       'profit':[]\n",
        "}\n",
        "statess=input('Enter State Name:-')\n",
        "for s in range (len(prediction_table['State'])):\n",
        "    if(prediction_table['State'][s]==statess):\n",
        "        if(prediction_table['Profit'][s]>1):\n",
        "          data1['crop'].append(prediction_table['Crop'][s])\n",
        "\n",
        "          data1['profit'].append(prediction_table['Profit'][s])   \n",
        "\n",
        "#plt.pie(data1['profit'], labels = data1['crop'])\n",
        "\n",
        "#data1=pd.DataFrame(data1)\n",
        "#data1[['profit','crop']].describe()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n#\\nplt.figure(figsize=((10,8)))\\ndata1={ 'crop':[],\\n       'profit':[]\\n}\\nstatess=input('Enter State Name:-')\\nfor s in range (len(prediction_table['State'])):\\n    if(prediction_table['State'][s]==statess):\\n        if(prediction_table['Profit'][s]>1):\\n          data1['crop'].append(prediction_table['Crop'][s])\\n\\n          data1['profit'].append(prediction_table['Profit'][s])   \\n\\n#plt.pie(data1['profit'], labels = data1['crop'])\\n\\n#data1=pd.DataFrame(data1)\\n#data1[['profit','crop']].describe()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO9834u93-Wo"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "profit_data = pd.read_csv(\"spd.csv\")\n",
        "profit_data = pd.DataFrame(np.matrix(profit_data),\n",
        "           columns=('state','crop','profit')\n",
        "                 )\n",
        "\n",
        "profit_data['state']=profit_data['state'].astype('category')\n",
        "profit_data['crop'] = profit_data['crop'].astype('category')\n",
        "\n",
        "profit_data['state_code'] = profit_data['state'].cat.codes\n",
        "profit_data['crop_code'] = profit_data['crop'].cat.codes\n",
        "\n",
        "mid = pd.unique(profit_data[['state', 'state_code']].values.ravel('K'))\n",
        "state_encoding = pd.DataFrame({\"state\":mid[:35], \"code\":mid[35:]})\n",
        "\n",
        "mid1 = pd.unique(profit_data[['crop', 'crop_code']].values.ravel('K'))\n",
        "crop_encoding = pd.DataFrame({\"crop\":mid1[:17], \"code\":mid1[17:]})\n",
        "\n",
        "state_encoding.to_csv(\"statecode.csv\", index=False)\n",
        "crop_encoding.to_csv(\"cropcode.csv\", index = False)\n",
        "\n",
        "dataset = pd.DataFrame({\"state\": profit_data[\"state_code\"], \"crop\": profit_data[\"crop_code\"], \"profit\": profit_data[\"profit\"].apply(lambda x: int(x))})\n",
        "columns = [\"state\", \"crop\", \"profit\"]\n",
        "dataset[columns].to_csv(\"encoded_dataset.csv\", index = False, header = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRagHwua-PIp"
      },
      "source": [
        "#pip uninstall tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K50P_P8I92of"
      },
      "source": [
        "#pip install tensorflow==1.13.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ls5Nm0ZBs7P"
      },
      "source": [
        "def del_all_flags(FLAGS):\n",
        "    flags_dict = FLAGS._flags()    \n",
        "    keys_list = [keys for keys in flags_dict]    \n",
        "    for keys in keys_list:\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "del_all_flags(tf.flags.FLAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 742
        },
        "id": "Q5cw6jjc9W_W",
        "outputId": "eb7c8dcf-e6f9-4916-d405-9252def3f245"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
        "from tensorflow.contrib.tensor_forest.client import random_forest\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import argparse\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"cropdata.csv\")\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "l1 = df[\"Soil\"]\n",
        "le.fit(l1)\n",
        "newsoil = le.transform(l1)\n",
        "df[\"Soil\"]=newsoil\n",
        "\n",
        "l2 = df[\"Month\"]\n",
        "le.fit(l2)\n",
        "df[\"Month\"]=le.transform(l2)\n",
        "\n",
        "l3 = df[\"State\"]\n",
        "le.fit(l3)\n",
        "df[\"State\"]=le.transform(l3)\n",
        "\n",
        "df=df.iloc[:,1:]\n",
        "df = pd.DataFrame(data = df.iloc[1:,:].values)\n",
        "\n",
        "print(df)\n",
        "df.to_csv('datafile.csv', index=False)\n",
        "\n",
        "\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "flags.DEFINE_string('model_dir', '', 'Base directory for output models.')\n",
        "flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data')\n",
        "\n",
        "flags.DEFINE_integer('train_steps', '1000', 'Number of training steps.')\n",
        "flags.DEFINE_string('batch_size', '1000','Number of examples in a training batch.')\n",
        "flags.DEFINE_integer('num_trees', '100', 'Number of trees in the forest.')\n",
        "flags.DEFINE_integer('max_nodes', '1000', 'Max total nodes in a single tree.')\n",
        "\n",
        "\n",
        "def build_estimator(model_dir):\n",
        "  params = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\n",
        "      num_classes=15, num_features=3,\n",
        "      num_trees=FLAGS.num_trees, max_nodes=FLAGS.max_nodes)\n",
        "  return random_forest.TensorForestEstimator(params, model_dir=model_dir)\n",
        "\n",
        "\n",
        "def train_and_eval():\n",
        "  model_dir = tempfile.mkdtemp() if not FLAGS.model_dir else FLAGS.model_dir\n",
        "  print('model directory = %s' % model_dir)\n",
        "\n",
        "  estimator = build_estimator(model_dir)\n",
        "\n",
        "  early_stopping_rounds = 100\n",
        "  check_every_n_steps = 100\n",
        "  monitor = random_forest.LossMonitor(early_stopping_rounds,\n",
        "                                                  check_every_n_steps)\n",
        "\n",
        "\n",
        "\n",
        "  feat = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)\n",
        "\n",
        "  estimator.fit(x=feat, y=mnist.train.labels,batch_size=FLAGS.batch_size,monitors=[monitor])\n",
        "\n",
        "  results = estimator.evaluate(x=mnist.test.images, y=mnist.test.labels,\n",
        "                               batch_size=FLAGS.batch_size)\n",
        "  for key in sorted(results):\n",
        "    print('%s: %s' % (key, results[key]))\n",
        "\n",
        "\n",
        "def main(_):\n",
        "  train_and_eval()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  tf.app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     0   1   2   3   4   5   6   7   8   9   10  11\n",
            "0     0   4   1   1   0   0   0   0   0   0   0   0\n",
            "1     0   4   2   1   0   0   0   0   0   0   0   0\n",
            "2     0   4   4   1   0   0   0   0   0   0   0   0\n",
            "3     0   4   6   1   0   0   0   0   0   0   0   0\n",
            "4     0   4   5   1   0   0   0   0   0   0   0   0\n",
            "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..\n",
            "789   2   9  10   0   0   0   0   0   0   0   0   1\n",
            "790   2   9  13   0   0   0   0   0   0   0   0   1\n",
            "791   2   9  14   0   0   0   0   0   0   0   0   1\n",
            "792   2   9  17   0   0   0   0   0   0   0   0   1\n",
            "793   2   9  16   0   0   0   0   0   0   0   0   1\n",
            "\n",
            "[794 rows x 12 columns]\n",
            "model directory = /tmp/tmprgc63rue\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f93335ac4d0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
            "  per_process_gpu_memory_fraction: 1.0\n",
            "}\n",
            ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/tmprgc63rue'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-4d65ab5e3eab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4d65ab5e3eab>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m   \u001b[0mtrain_and_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-4d65ab5e3eab>\u001b[0m in \u001b[0;36mtrain_and_eval\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0mearly_stopping_rounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0mcheck_every_n_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m   monitor = random_forest.LossMonitor(early_stopping_rounds,\n\u001b[0m\u001b[1;32m     67\u001b[0m                                                   check_every_n_steps)\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.contrib.tensor_forest.client.random_forest' has no attribute 'LossMonitor'"
          ]
        }
      ]
    }
  ]
}